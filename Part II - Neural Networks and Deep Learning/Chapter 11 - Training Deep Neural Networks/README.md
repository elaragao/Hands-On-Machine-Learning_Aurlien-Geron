# Training Deep Neural Networks

The previous chapter presented solutions to somewhat simpler problems. Now, if one wants to address more complex problems, such as detecting multiple objects in images, more elaborate methods will be necessary.

Problems such as slow training, little data, _overfitting_ of thousands of parameters, gradient adjustments, etc. This chapter will address these and other possible problems, as well as techniques to overcome and solve them.

<!------------------------------------------------------>
<!------------------------------------------------------>
<!------------------------------------------------------>
# The Vanishing/Exploding Gradients Problems



<!------------------------------------------------------>
<!------------------------------------------------------>
## Glorot and He Initialization



<!------------------------------------------------------>
<!------------------------------------------------------>
## Better Activation Functions



<!------------------------------------------------------>
<!------------------------------------------------------>
## Batch Normalization



<!------------------------------------------------------>
<!------------------------------------------------------>
## Gradient Clipping





<!------------------------------------------------------>
<!------------------------------------------------------>
<!------------------------------------------------------>
# Reusing Pretrained Layers



<!------------------------------------------------------>
<!------------------------------------------------------>
## Transfer Learning with Keras



<!------------------------------------------------------>
<!------------------------------------------------------>
## Unsupervised Pretraining



<!------------------------------------------------------>
<!------------------------------------------------------>
## Pretraining on an Auxiliary Task


<!------------------------------------------------------>
<!------------------------------------------------------>
<!------------------------------------------------------>
# Faster Optimizers



<!------------------------------------------------------>
<!------------------------------------------------------>
## Momentum



<!------------------------------------------------------>
<!------------------------------------------------------>
## Nesterov Accelerated Gradient



<!------------------------------------------------------>
<!------------------------------------------------------>
## AdaGrad



<!------------------------------------------------------>
<!------------------------------------------------------>
## RMSProp



<!------------------------------------------------------>
<!------------------------------------------------------>
## Adam



<!------------------------------------------------------>
<!------------------------------------------------------>
## AdaMax



<!------------------------------------------------------>
<!------------------------------------------------------>
## Nadam



<!------------------------------------------------------>
<!------------------------------------------------------>
## AdamW



<!------------------------------------------------------>
<!------------------------------------------------------>
<!------------------------------------------------------>
# Learning Rate Scheduling



<!------------------------------------------------------>
<!------------------------------------------------------>
<!------------------------------------------------------>
# Avoiding Overfitting Through Regularization



<!------------------------------------------------------>
<!------------------------------------------------------>
## ℓ1 and ℓ2 Regularization



<!------------------------------------------------------>
<!------------------------------------------------------>
## Dropout



<!------------------------------------------------------>
<!------------------------------------------------------>
## Monte Carlo (MC) Dropout



<!------------------------------------------------------>
<!------------------------------------------------------>
## Max-Norm Regularization



<!------------------------------------------------------>
<!------------------------------------------------------>
<!------------------------------------------------------>
# Summary and Practical Guidelines
